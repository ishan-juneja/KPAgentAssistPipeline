{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16fbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b01ea747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaxonomyLabeler:\n",
    "    def __init__(self, taxonomy_labels, model_name='all-mpnet-base-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the labeler with taxonomy labels and load the embedding model.\n",
    "        \"\"\"\n",
    "        self.taxonomy_labels = taxonomy_labels\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.label_embeddings = self.model.encode(taxonomy_labels, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "    def label_errors(self, error_texts, threshold=0.6):\n",
    "        \"\"\"\n",
    "        Assign taxonomy labels to a list of error texts.\n",
    "        If threshold is provided, assign 'Other' if similarity below threshold.\n",
    "        Returns:\n",
    "            labels: list of label strings\n",
    "            scores: list of highest similarity scores\n",
    "        \"\"\"\n",
    "        error_embeddings = self.model.encode(error_texts, convert_to_tensor=True, show_progress_bar=True)\n",
    "        cosine_scores = util.cos_sim(error_embeddings, self.label_embeddings)\n",
    "        max_scores, best_indices = torch.max(cosine_scores, dim=1)\n",
    "\n",
    "        labels = []\n",
    "        for score, idx in zip(max_scores, best_indices):\n",
    "            if threshold is not None and score < threshold:\n",
    "                labels.append(\"Other\")\n",
    "            else:\n",
    "                labels.append(self.taxonomy_labels[idx])\n",
    "\n",
    "        return labels, max_scores.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2454535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_errors_with_taxonomy(df, new_csv=\"final_labeled_errors.csv\"):\n",
    "    taxonomy_labels = [\n",
    "        \"Confusion About Leave Request Submission or Approval\",\n",
    "        \"Unclear FMLA or Bonding Eligibility Criteria\",\n",
    "        \"Knowledge Base Articles Missing or Not Relevant\",\n",
    "        \"Paycheck Errors, Deductions, or Overpayment Disputes\",\n",
    "        \"Inability to Access HR Systems or Forms\",\n",
    "        \"Employees Unaware of Leave Types or Benefit Interactions\",\n",
    "        \"Difficulty Providing Documentation or Verifying Identity\",\n",
    "        \"Lack of Clear Rules for Leave Accrual and Usage\",\n",
    "        \"Complex or Confusing Enrollment Processes\",\n",
    "        \"Unclear Disability Insurance Procedures\",\n",
    "        \"Delays in Processing or Approving Requests\",\n",
    "        \"Region-Specific Policy or Escalation Confusion\",\n",
    "        \"Inadequate or Vague Communication to Employees\",\n",
    "        \"Generic or Unclassifiable Issues\"\n",
    "    ]\n",
    "    labeler = TaxonomyLabeler(taxonomy_labels)\n",
    "    error_texts = df[\"Knowledge_Answer\"].fillna(\"\").astype(str).tolist()\n",
    "    labels, scores = labeler.label_errors(error_texts, threshold=0.3)\n",
    "    df[\"Parent Error Topic\"] = labels\n",
    "    df[\"Parent Error Similarity Score\"] = scores\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2240239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Query_Type  Feedback      Conversation_Topic  Conversation_Subtopic  \\\n",
      "0          -  positive  Accurate Summarization                    NaN   \n",
      "1          -  positive  Accurate Summarization                    NaN   \n",
      "2          -  positive  Accurate Summarization                    NaN   \n",
      "3          -  positive  Accurate Summarization                    NaN   \n",
      "4          -  positive  Accurate Summarization                    NaN   \n",
      "\n",
      "                                    Knowledge_Answer Knowledge Agent_ID  \\\n",
      "0  status salary advance payment ment hour approv...         -  S522948   \n",
      "1  status salary advance payment ment hour approv...         -  S522948   \n",
      "2  status modify payment arrangement document sen...         -  S522948   \n",
      "3  status modify payment arrangement document sen...         -  S522948   \n",
      "4  add guardian benefit emergency basis health ca...         -  S160879   \n",
      "\n",
      "             Timestamp Summary_Reason  \\\n",
      "0  2025-05-17 00:58:20              -   \n",
      "1  2025-05-17 00:58:07              -   \n",
      "2  2025-05-17 00:52:40              -   \n",
      "3  2025-05-17 00:52:02              -   \n",
      "4  2025-05-17 00:50:10              -   \n",
      "\n",
      "                                         Source_File day_of_week  hour_of_day  \\\n",
      "0  Kaiser Permanente - Agent Assist HR Feedback (...    Saturday            0   \n",
      "1  Kaiser Permanente - Agent Assist HR Feedback (...    Saturday            0   \n",
      "2  Kaiser Permanente - Agent Assist HR Feedback (...    Saturday            0   \n",
      "3  Kaiser Permanente - Agent Assist HR Feedback (...    Saturday            0   \n",
      "4  Kaiser Permanente - Agent Assist HR Feedback (...    Saturday            0   \n",
      "\n",
      "   conversation_length   Parent Category Topic  \\\n",
      "0                   28  Payroll / Compensation   \n",
      "1                   28  Payroll / Compensation   \n",
      "2                   45  Payroll / Compensation   \n",
      "3                   45  Payroll / Compensation   \n",
      "4                   51   Enrollment & Benefits   \n",
      "\n",
      "   Parent Category Similarity_Score  \n",
      "0                          0.476088  \n",
      "1                          0.476088  \n",
      "2                          0.380943  \n",
      "3                          0.380943  \n",
      "4                          0.503583  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "Batches: 100%|██████████| 547/547 [49:08<00:00,  5.39s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_dataset_july_7_2.csv\n"
     ]
    }
   ],
   "source": [
    "send_df = pd.read_csv(\"final_dataset_july_7.csv\")\n",
    "print(send_df.head(5))\n",
    "my_df = label_errors_with_taxonomy(df=send_df, new_csv=\"final_dataset_july_7_2.csv\")\n",
    "my_df.to_csv(\"final_dataset_july_7_3.csv\", index=False)\n",
    "print(\"final_dataset_july_7_2.csv\")\n",
    "# df = pd.read_csv(\"final_dataset_july_7.csv\")\n",
    "# label_errors_with_taxonomy(df=df, new_csv=\"final_dataset_july_7_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cee0ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m my_df\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmy_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(new_csv, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved to CSV\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "my_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82441dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Count rows below threshold\n",
    "    threshold = 0.3\n",
    "    num_below_threshold = (df[\"Similarity_Score\"] < threshold).sum()\n",
    "    num_total = len(df)\n",
    "    percent_below = (num_below_threshold / num_total) * 100\n",
    "\n",
    "      # Count rows above threshold\n",
    "    num_above_threshold = num_total - num_below_threshold\n",
    "    percent_above = 100 - percent_below\n",
    "\n",
    "    # Print counts and percentages\n",
    "    print(\"\\n=== Similarity Score Summary ===\")\n",
    "    print(f\"Total records: {num_total}\")\n",
    "    print(f\"Records below threshold ({threshold}): {num_below_threshold} ({percent_below:.2f}%)\")\n",
    "    print(f\"Records above threshold: {num_above_threshold} ({percent_above:.2f}%)\")\n",
    "\n",
    "    # Create a simple ASCII bar chart\n",
    "    print(\"\\n[ASCII Bar Chart]\")\n",
    "    bar_length = 50\n",
    "\n",
    "    # Calculate proportional bar lengths\n",
    "    below_bar = int((num_below_threshold / num_total) * bar_length)\n",
    "    above_bar = bar_length - below_bar\n",
    "\n",
    "    print(f\"Below Threshold  : {'#' * below_bar}{' ' * above_bar} ({percent_below:.2f}%)\")\n",
    "    print(f\"Above Threshold  : {'#' * above_bar}{' ' * below_bar} ({percent_above:.2f}%)\")\n",
    "\n",
    "    # Plot histogram\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(df[\"Similarity_Score\"], bins=20, color=\"steelblue\", edgecolor=\"black\")\n",
    "\n",
    "    # Add threshold line\n",
    "    threshold = 0.3\n",
    "    plt.axvline(threshold, color=\"red\", linestyle=\"--\", linewidth=1.5, label=f\"Threshold = {threshold}\")\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(\"Distribution of Similarity Scores\")\n",
    "    plt.xlabel(\"Similarity Score\")\n",
    "    plt.ylabel(\"Number of Records\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
